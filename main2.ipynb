{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile('Template v2.xlsx')\n",
    "\n",
    "# Get the list of sheet names\n",
    "sheet_names = excel_file.sheet_names\n",
    "\n",
    "# Print the list of sheet names\n",
    "print(f'Available sheets in the file are- {sheet_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sheets into dataframes\n",
    "Mapping_df = pd.read_excel(excel_file, sheet_name=\"Mapping\")\n",
    "BaseCapacity_df = pd.read_excel(excel_file, sheet_name=\"Base Capacity\")\n",
    "Support_Capacity_df = pd.read_excel(excel_file, sheet_name=\"Support Capacity\")\n",
    "Support_df = pd.read_excel(excel_file, sheet_name=\"Support\")\n",
    "Bi_Inputs_df = pd.read_excel(excel_file, sheet_name=\"BI Inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col = ['Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping Sheet Data Workings\n",
    "\n",
    "# Select only the \"OU\" and \"Facility Name\" columns\n",
    "OU_Facility_df = Mapping_df[['OU', 'Facility Name']]\n",
    "# Remove duplicates from OU_Facility_df\n",
    "OU_Facility_df = OU_Facility_df.drop_duplicates(subset='OU')\n",
    "\n",
    "# Select only the \"OU\", and \"City\" columns\n",
    "OU_City_df = Mapping_df[['OU', 'City']]\n",
    "# Remove duplicates from OU_City_df\n",
    "OU_City_df = OU_City_df.drop_duplicates(subset='OU')\n",
    "\n",
    "# Select only the \"OU\", and \"BI\" columns this is only used for BI inputs BI Geo validation\n",
    "OU_BIGeo_df = Mapping_df[['OU', 'BI Geo']]\n",
    "# Remove duplicates from OU_BIGeo_df\n",
    "OU_BIGeo_df = OU_BIGeo_df.drop_duplicates(subset='OU')\n",
    "\n",
    "# Select only the \"BI Geo\", and \"Geo\" columns\n",
    "BIGeo_Geo_df = Mapping_df[['BI Geo', 'Geo']]\n",
    "# Remove duplicates from BIGeo_Geo_df This is mandatory to remove duplicate entries\n",
    "BIGeo_Geo_df = BIGeo_Geo_df.drop_duplicates(subset='BI Geo')\n",
    "\n",
    "# Select only the \"BI Geo\", and \"Geo Type\" columns\n",
    "BIGeo_GeoType_df = Mapping_df[['BI Geo', 'Geo Type']]\n",
    "# Remove duplicates from BIGeo_GeoType_df This is mandatory to remove duplicate entries\n",
    "BIGeo_GeoType_df = BIGeo_GeoType_df.drop_duplicates(subset='BI Geo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BI Inputs Sheet Data Working\n",
    "# Rename specific columns\n",
    "Bi_Inputs_df = Bi_Inputs_df.rename(columns={\n",
    "    \"LE[Scenario]\": \"FCST\",\n",
    "    \"LE[Client]\": \"Customer\",\n",
    "    \"LE[Horizontal]\": \"Horizontal\",\n",
    "    \"LE[Stage]\": \"Stage\",\n",
    "    \"LE[Vertical]\": \"Vertical\",\n",
    "    \"LE[SD_Geo]\": \"BI Geo\",\n",
    "    \"LE[OU_DESCR]\": \"OU\",\n",
    "    \"LE[Project_DESCR]\": \"Program Name\",\n",
    "    \"LE[Account]\": \"Account\",\n",
    "    \"LE[Year]\": \"FY\",\n",
    "    \"[SumJul]\": \"Jul\",\n",
    "    \"[SumAug]\": \"Aug\",\n",
    "    \"[SumSep]\": \"Sep\",\n",
    "    \"[SumOct]\": \"Oct\",\n",
    "    \"[SumNov]\": \"Nov\",\n",
    "    \"[SumDec]\": \"Dec\",\n",
    "    \"[SumJan]\": \"Jan\",\n",
    "    \"[SumFeb]\": \"Feb\",\n",
    "    \"[SumMar]\": \"Mar\",\n",
    "    \"[SumApr]\": \"Apr\",\n",
    "    \"[SumMay]\": \"May\",\n",
    "    \"[SumJun]\": \"Jun\"\n",
    "})\n",
    "\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"FCST\", \"Customer\", \"Horizontal\", \"Stage\", \"Vertical\", \n",
    "    \"BI Geo\", \"OU\", \"Program Name\", \"FY\", \"Account\"]+numerical_col\n",
    "    \n",
    "# Select only the specified columns\n",
    "Bi_Inputs_df = Bi_Inputs_df[columns_to_keep]\n",
    "\n",
    "#Fillter Account to select only Seats for Allocation_Adj_Store\n",
    "Bi_Inputs_df = Bi_Inputs_df[Bi_Inputs_df['Account'] == \"Seats for Allocation_Adj_Store\"]\n",
    "\n",
    "\n",
    "# Define a function to determine the 'Seat Type' based on the 'Stage' value\n",
    "def determine_seat_type(stage):\n",
    "    if stage == 'Existing':\n",
    "        return 'Production'\n",
    "    elif stage == 'Stage 5':\n",
    "        return 'BD Stage 5'\n",
    "    elif stage in ['Stage 3', 'Stage 4']:\n",
    "        return 'BD Stage 3 & 4'\n",
    "    else:\n",
    "        return 'BD Stage 2 & Below'\n",
    "    \n",
    "# Apply the function to create the new column 'Seat Type'\n",
    "Bi_Inputs_df['Seat Type'] = Bi_Inputs_df['Stage'].apply(determine_seat_type)\n",
    "\n",
    "# Keep only the first 4 characters of the 'OU' column\n",
    "Bi_Inputs_df['OU'] = Bi_Inputs_df['OU'].str.slice(0, 4)\n",
    "\n",
    "# Remove the first 2 characters from the 'Customer' column\n",
    "Bi_Inputs_df['Customer'] = Bi_Inputs_df['Customer'].str.slice(2)\n",
    "\n",
    "# Remove the last 2 characters from the 'Vertical' column\n",
    "Bi_Inputs_df['Vertical'] = Bi_Inputs_df['Vertical'].str.slice(0, -2)\n",
    "\n",
    "# Remove the last 2 characters from the 'Horizontal' column\n",
    "Bi_Inputs_df['Horizontal'] = Bi_Inputs_df['Horizontal'].str.slice(0, -2)\n",
    "\n",
    "# Create a new column 'Job Code' based on the provided conditions\n",
    "Bi_Inputs_df['Job Code'] = Bi_Inputs_df['Program Name'].apply(lambda x: x[:5] if x[:1].isdigit() else x[:18])\n",
    "\n",
    "# Merge the dataframes on the 'OU' column\n",
    "Bi_Inputs_df = pd.merge(Bi_Inputs_df, OU_Facility_df, on='OU', how='left')\n",
    "Bi_Inputs_df = pd.merge(Bi_Inputs_df, OU_City_df, on='OU', how='left')\n",
    "Bi_Inputs_df = pd.merge(Bi_Inputs_df, OU_BIGeo_df, on='OU', how='left')\n",
    "\n",
    "\n",
    "# Replace 'BI Geo_x' with 'BI Geo_y' where they are not equal\n",
    "Bi_Inputs_df['BI Geo_x'] = np.where(Bi_Inputs_df['BI Geo_x'] != Bi_Inputs_df['BI Geo_y'], Bi_Inputs_df['BI Geo_y'], Bi_Inputs_df['BI Geo_x'])\n",
    "\n",
    "# Drop the 'BI Geo_y' column\n",
    "Bi_Inputs_df = Bi_Inputs_df.drop(columns=['BI Geo_y'])\n",
    "\n",
    "# Rename 'BI Geo_x' to 'BI Geo'\n",
    "Bi_Inputs_df = Bi_Inputs_df.rename(columns={'BI Geo_x': 'BI Geo'})\n",
    "\n",
    "# replace NaN values with zero. This is optional if incase there is no value provided.\n",
    "Bi_Inputs_df[numerical_col] = Bi_Inputs_df[numerical_col].fillna(0)\n",
    "\n",
    "# Convert month column data types to integer using numerical_col\n",
    "Bi_Inputs_df[numerical_col] = Bi_Inputs_df[numerical_col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Working to get all row items\n",
    "\n",
    "# Create combined index of all unique rows based on OU and BI Geo\n",
    "all_rows = pd.concat([BaseCapacity_df[[\"OU\",\"BI Geo\"]],Support_Capacity_df[[\"OU\",\"BI Geo\"]],Support_df[[\"OU\",\"BI Geo\"]],Bi_Inputs_df[[\"OU\",\"BI Geo\"]]]).drop_duplicates()\n",
    "\n",
    "# reindex Based Capacity to include all unique rows\n",
    "BaseCapacity_df = BaseCapacity_df.set_index([\"OU\",\"BI Geo\"]).reindex(all_rows.set_index([\"OU\",\"BI Geo\"]).index,fill_value=0).reset_index()\n",
    "Support_Capacity_df = Support_Capacity_df.set_index([\"OU\",\"BI Geo\"]).reindex(all_rows.set_index([\"OU\",\"BI Geo\"]).index,fill_value=0).reset_index()\n",
    "\n",
    "# Add other columns data\n",
    "# Identify the most common non-zero value in the \"FY\" column\n",
    "most_common_value = BaseCapacity_df.loc[BaseCapacity_df[\"FY\"] != 0, \"FY\"].mode()[0]\n",
    "most_common_value = Support_Capacity_df.loc[Support_Capacity_df[\"FY\"] != 0, \"FY\"].mode()[0]\n",
    "\n",
    "# Replace 0 with the most common non-zero value using a lambda function\n",
    "BaseCapacity_df[\"FY\"] = BaseCapacity_df[\"FY\"].apply(lambda x: most_common_value if x == 0 else x)\n",
    "Support_Capacity_df[\"FY\"] = Support_Capacity_df[\"FY\"].apply(lambda x: most_common_value if x == 0 else x)\n",
    "\n",
    "# You can use the inplace parameter to modify the DataFrame directly\n",
    "BaseCapacity_df.drop([\"Facility Name\"], axis=1, inplace=True)\n",
    "Support_Capacity_df.drop([\"Facility Name\"], axis=1, inplace=True)\n",
    "\n",
    "# Add Facility Name Again for all rows based on OU\n",
    "BaseCapacity_df = pd.merge(BaseCapacity_df, OU_Facility_df, on='OU', how='left')\n",
    "Support_Capacity_df = pd.merge(Support_Capacity_df, OU_Facility_df, on='OU', how='left')\n",
    "\n",
    "BaseCapacity_df[\"Seat Type\"] = \"Base Capacity\"\n",
    "Support_Capacity_df[\"Seat Type\"] = \"Support Capacity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the value from the first row of the \"FCST\" column\n",
    "Scenario = Bi_Inputs_df.loc[0, \"FCST\"]\n",
    "\n",
    "Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "Existing_Total_df = Bi_Inputs_df\n",
    "BD_3andAbove_Total_df = Bi_Inputs_df\n",
    "BD_2andBelow_Total_df = Bi_Inputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "StageLevelExisting = ['Existing']\n",
    "StageLevel3to5 = ['Stage 3','Stage 4','Stage 5']\n",
    "StageLevel2toBelow = ['Stage 1', 'Stage 2', 'Stage_Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows based on Stage\n",
    "Existing_Total_df = Existing_Total_df[Existing_Total_df['Stage'].isin(StageLevelExisting)]\n",
    "BD_3andAbove_Total_df = BD_3andAbove_Total_df[BD_3andAbove_Total_df['Stage'].isin(StageLevel3to5)]\n",
    "BD_2andBelow_Total_df = BD_2andBelow_Total_df[BD_2andBelow_Total_df['Stage'].isin(StageLevel2toBelow)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the data to have single row item data for all \n",
    "Existing_Total_df = Existing_Total_df.groupby([\"FY\",\"FCST\",'BI Geo',\"Facility Name\" ,'OU',\"City\"])[numerical_col].sum().reset_index().fillna(0)\n",
    "BD_3andAbove_Total_df = BD_3andAbove_Total_df.groupby([\"FY\",\"FCST\",'BI Geo',\"Facility Name\" ,'OU',\"City\"])[numerical_col].sum().reset_index().fillna(0)\n",
    "BD_2andBelow_Total_df = BD_2andBelow_Total_df.groupby([\"FY\",\"FCST\",'BI Geo',\"Facility Name\" ,'OU', \"City\"])[numerical_col].sum().reset_index().fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Capacity Sheet Data Working\n",
    "\n",
    "# Grouping to sum up Base capacity if incase multiple entries or do manual check to remove duplicates from raw data\n",
    "BaseCapacity_df = BaseCapacity_df.groupby([\"FY\",'OU','BI Geo',\"Facility Name\" ,\"Seat Type\"])[numerical_col].sum().reset_index().fillna(0)\n",
    "\n",
    "# Merge the dataframes on the 'OU' column\n",
    "BaseCapacity_df = pd.merge(BaseCapacity_df, OU_City_df, on='OU', how='left')\n",
    "\n",
    "# Add FCST column\n",
    "BaseCapacity_df['FCST']= Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Capacity Sheet Data Working\n",
    "\n",
    "# Grouping to sum up Support capacity if incase multiple entries or do manual check to remove duplicates from raw data\n",
    "Support_Capacity_df = Support_Capacity_df.groupby([\"FY\",'OU','BI Geo',\"Facility Name\" ,\"Seat Type\"])[numerical_col].sum().reset_index().fillna(0)\n",
    "\n",
    "# Merge the dataframes on the 'OU' column\n",
    "Support_Capacity_df = pd.merge(Support_Capacity_df, OU_City_df, on='OU', how='left')\n",
    "# replace NaN values with zero. This is optional if incase there is no value provided.\n",
    "Support_Capacity_df[numerical_col] = Support_Capacity_df[numerical_col].fillna(0)\n",
    "\n",
    "# Add FCST column\n",
    "Support_Capacity_df['FCST']= Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Sheet Data Working\n",
    "#Fillter Sum column to remove rows if its value is 0\n",
    "Support_df = Support_df[Support_df['Sum'] != 0]\n",
    "# Merge the dataframes on the 'OU' column\n",
    "Support_df = pd.merge(Support_df, OU_City_df, on='OU', how='left')\n",
    "# replace NaN values with zero. This is optional if incase there is no value provided.\n",
    "Support_df[numerical_col] = Support_df[numerical_col].fillna(0)\n",
    "\n",
    "# Add FCST column\n",
    "Support_df['FCST']= Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Working for calculations\n",
    "# Set index for each DataFrame without inplace=True\n",
    "BaseCapacity_df = BaseCapacity_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"])\n",
    "Support_Capacity_df = Support_Capacity_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"])\n",
    "\n",
    "# Align the indexes and fill missing rows/values with 0\n",
    "all_indexes = BaseCapacity_df.index.union(Support_Capacity_df.index).union(\n",
    "    Existing_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).index\n",
    ").union(\n",
    "    BD_3andAbove_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).index\n",
    ").union(\n",
    "    BD_2andBelow_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).index\n",
    ")\n",
    "\n",
    "BaseCapacity_df = BaseCapacity_df.reindex(all_indexes, fill_value=0)\n",
    "Support_Capacity_df = Support_Capacity_df.reindex(all_indexes, fill_value=0)\n",
    "EX_df = Existing_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).reindex(all_indexes, fill_value=0)\n",
    "BD_3andAbove_df = BD_3andAbove_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).reindex(all_indexes, fill_value=0)\n",
    "BD_2andBelow_df = BD_2andBelow_Total_df.set_index([\"OU\", \"Facility Name\", \"FY\", \"BI Geo\", \"City\"]).reindex(all_indexes, fill_value=0)\n",
    "\n",
    "# Perform the calculations with NaN values replaced by 0\n",
    "FS_afterSD_df = BaseCapacity_df[numerical_col].fillna(0) - (Support_Capacity_df[numerical_col].fillna(0) + EX_df[numerical_col].fillna(0))\n",
    "FS_afterBD3andAbove_df = BaseCapacity_df[numerical_col].fillna(0) - (Support_Capacity_df[numerical_col].fillna(0) + EX_df[numerical_col].fillna(0) + BD_3andAbove_df[numerical_col].fillna(0))\n",
    "FS_afterAllBD_df = BaseCapacity_df[numerical_col].fillna(0) - (Support_Capacity_df[numerical_col].fillna(0) + EX_df[numerical_col].fillna(0) + BD_3andAbove_df[numerical_col].fillna(0) + BD_2andBelow_df[numerical_col].fillna(0))\n",
    "\n",
    "# Reset index to bring back the index columns\n",
    "FS_afterSD_df = FS_afterSD_df.reset_index()\n",
    "FS_afterBD3andAbove_df = FS_afterBD3andAbove_df.reset_index()\n",
    "FS_afterAllBD_df = FS_afterAllBD_df.reset_index()\n",
    "\n",
    "# Add Seat Type column\n",
    "FS_afterSD_df['Seat Type'] = \"Free Seats After SD\"\n",
    "FS_afterBD3andAbove_df['Seat Type'] = \"Free Seats After BD Stage 3 and Above\"\n",
    "FS_afterAllBD_df['Seat Type'] = \"Free Seats After all BD\"\n",
    "\n",
    "# Add FCST column\n",
    "FS_afterSD_df['FCST'] = Scenario\n",
    "FS_afterBD3andAbove_df['FCST'] = Scenario\n",
    "FS_afterAllBD_df['FCST'] = Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New working for Production Capacity\n",
    "# Define the column headers\n",
    "index_columns = [\"FY\", \"BI Geo\", \"Facility Name\", \"OU\",]\n",
    "\n",
    "# Create an empty DataFrame with the specified headers\n",
    "Pro_Capacity_df = pd.DataFrame(columns=index_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseCapacity_df = BaseCapacity_df.reset_index()\n",
    "Support_Capacity_df = Support_Capacity_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set index for each DataFrame without inplace=True\n",
    "BaseCapacity_df = BaseCapacity_df.set_index(index_columns)\n",
    "Support_Capacity_df = Support_Capacity_df.set_index(index_columns)\n",
    "\n",
    "# Create the combined index\n",
    "all_indexes = BaseCapacity_df.index.union(Support_Capacity_df.index).union(\n",
    "    Pro_Capacity_df.set_index(index_columns).index\n",
    ")\n",
    "\n",
    "BaseCapacity_df = BaseCapacity_df.reindex(all_indexes, fill_value=0)\n",
    "Support_Capacity_df = Support_Capacity_df.reindex(all_indexes, fill_value=0)\n",
    "Pro_Capacity_df = Pro_Capacity_df.set_index(index_columns).reindex(all_indexes, fill_value=0)\n",
    "\n",
    "# Perform the calculations with NaN values replaced by 0\n",
    "Pro_Capacity_df = BaseCapacity_df[numerical_col].fillna(0) - Support_Capacity_df[numerical_col].fillna(0)\n",
    "\n",
    "# Reset index to bring back the index columns\n",
    "Pro_Capacity_df = Pro_Capacity_df.reset_index()\n",
    "# Reset index to bring back the index columns Trial only for now not sure if this is making any difference in final output\n",
    "BaseCapacity_df = BaseCapacity_df.reset_index()\n",
    "Support_Capacity_df = Support_Capacity_df.reset_index()\n",
    "# Add Seat Type column\n",
    "Pro_Capacity_df['Seat Type'] = \"Production Capacity\"\n",
    "\n",
    "# Add FCST column\n",
    "Pro_Capacity_df['FCST'] = Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all required dataframes to make final GCD\n",
    "\n",
    "Final_df = pd.concat([BaseCapacity_df, Support_Capacity_df,Pro_Capacity_df, Support_df, Bi_Inputs_df, FS_afterSD_df,FS_afterBD3andAbove_df,FS_afterAllBD_df], ignore_index=True)\n",
    "\n",
    "# Replace NaN values with 0 in the specified numerical columns\n",
    "Final_df[numerical_col] = Final_df[numerical_col].fillna(0)\n",
    "\n",
    "# Replace NaN values in all other columns with \" - \"\n",
    "Final_df = Final_df.apply(lambda x: x.fillna(\" - \") if x.name not in numerical_col else x)\n",
    "\n",
    "# Convert month column data types to integer using numerical_col\n",
    "Final_df[numerical_col] = Final_df[numerical_col].astype(int)\n",
    "\n",
    "# Merge the dataframes on the 'BI Geo' column to get Geo\n",
    "Final_df = pd.merge(Final_df, BIGeo_Geo_df, on='BI Geo', how='left')\n",
    "\n",
    "# Merge the dataframes on the 'BI Geo' column to get Geo Type\n",
    "Final_df = pd.merge(Final_df, BIGeo_GeoType_df, on='BI Geo', how='left')\n",
    "\n",
    "# Create the new column 'SD Geo' by concatenating 'Geo Type' and 'Geo' columns\n",
    "Final_df[\"SD Geo\"] = Final_df[\"Geo Type\"] + \" \" +Final_df[\"Geo\"]\n",
    "Final_df[\"SD Geo OU\"]= Final_df[\"SD Geo\"] + \"_\" + Final_df[\"OU\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the columns in Final GCD\n",
    "Final_df = Final_df[['FCST', 'FY',  'BI Geo','Geo', \"SD Geo\",\"Geo Type\",\"SD Geo OU\",'OU', 'City', 'Facility Name', 'Vertical', 'Stage',\n",
    "                     'Job Code', 'Customer', 'Seat Type','Account', 'Jul', 'Aug', 'Sep', 'Oct',\n",
    "                     'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write all required data to new excel file\n",
    "# Try to export the merged dataframe to an Excel file\n",
    "try:\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    with pd.ExcelWriter('PythonGCD.xlsx', engine='xlsxwriter') as writer:\n",
    "        # Write each dataframe to a different worksheet.\n",
    "        \n",
    "        # Bi_Inputs_df.to_excel(writer, sheet_name='BI Inputs', index=False)\n",
    "        Final_df.to_excel(writer, sheet_name='Final GCD', index=False)\n",
    "    print(\"Data has been exported to 'PythonGCD.xlsx'\")\n",
    "except PermissionError:\n",
    "    print(\"The file 'PythonGCD.xlsx' is already open. Please close the file and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
